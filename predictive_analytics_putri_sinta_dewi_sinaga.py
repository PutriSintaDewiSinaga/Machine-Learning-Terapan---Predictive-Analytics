# -*- coding: utf-8 -*-
"""Predictive Analytics_Putri Sinta Dewi Sinaga.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P1ycqiizFeQGWmf2hjQsCIwVzWYVJaM3

# ***PROYEK PERTAMA MACHINE LEARNING TERAPAN***
## **"Diabetes Prediction"**
Oleh: Putri Sinta Dewi Sinaga

Download dataset from Kaggle
"""

# install kaggle package
!pip install -q kaggle

# upload kaggle.json
from google.colab import files
files.upload()

# make directory and change permission
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

# download dataset, choose 'copy api command' from kaggle dataset
!kaggle datasets download -d iammustafatz/diabetes-prediction-dataset

# unzip
!mkdir diabetes-prediction-dataset
!unzip diabetes-prediction-dataset.zip -d diabetes-prediction-dataset
!ls diabetes-prediction-dataset

# Commented out IPython magic to ensure Python compatibility.
# library
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import numpy as np

from imblearn.over_sampling import SMOTE #oversampling
from sklearn.preprocessing import StandardScaler #scaling
from sklearn.model_selection import train_test_split #splitting
from sklearn import preprocessing
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

# machine learning
from sklearn.svm import SVC #Support Vector Machine
from sklearn.ensemble import RandomForestClassifier #Random Forest
from sklearn.neighbors import KNeighborsClassifier #KNN

from sklearn.metrics import accuracy_score #accuracy measure
from sklearn.metrics import confusion_matrix #for confusion matrix
from sklearn.metrics import classification_report #report
from sklearn.impute import SimpleImputer

# ignore all future warnings
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

"""Importing the dataset"""

# read_csv
df = pd.read_csv('/content/diabetes-prediction-dataset/diabetes_prediction_dataset.csv')
df.head()

"""Analysis of dataset"""

# info
df.info()

"""analysis for Gender Column"""

df['gender'].value_counts()

# Label Encoding for gender column
label_encoder = preprocessing.LabelEncoder()
df['gender'] = label_encoder.fit_transform(df['gender'])
df

"""Analysis for Smoking History"""

df['smoking_history'].value_counts()

# Convert smoking history to numerical format
smoking_history_mapping = {'not current' : 4 , 'former' : 2 , 'No Info' : 0 , 'current' : 3 , 'never' : 1 , 'ever' : 5}
df['smoking_history'] = df['smoking_history'].map(smoking_history_mapping)

df

df.describe()

"""Analysis for Age column"""

df['age'].hist()

df = df[df['age'].mod(1) == 0]
df

# convert age column datatype to int
df['age'] = df['age'].astype(int)
df.head()

df.info()

"""**Data Cleaning**

proses mendeteksi dan mengoreksi (atau menghapus) catatan yang rusak atau tidak akurat dari kumpulan catatan, tabel, atau basis data dan mengacu pada pengidentifikasian bagian data yang tidak lengkap, salah, tidak akurat atau tidak relevan dan kemudian mengganti, memodifikasi, atau menghapus data kotor atau kasar.
"""

df.nunique()

# check missing values
(df.isnull() | df.empty | df.isna()).sum()

# check duplicates data
df.duplicated().sum()

# remove duplicates data
df.drop_duplicates(inplace=True)
if df.duplicated().sum() == 0:
  print('no duplicate instances')

# check dimensionality
df.shape

# descriptive statistics
df.describe().transpose()

"""Pada proses cleansing data, dataset yang digunakan memiliki duplikasi data sebanyak 3849 data. duplikasi ini harus dihilangkan untuk mencegah ketidakuratan model dalam melakukan prediksi. data yang terduplikasi memang cukup banyak tetapi masih bisa dipakai karena masih terdapat 94133 data untuk digunakan.

**Exploratory Data Analysis**

Exploratory Data Analysis adalah suatu proses uji investigasi awal yang bertujuan untuk mengidentifikasi pola, menemukan anomali, menguji hipotesis dan memeriksa asumsi. Proses EDA ini sangat bermanfaat dalam proses analisis statistik.
"""

# convert numerical to categorical
def categorization(data):
  df.astype({'gender': 'object'},{'diabetes': 'object'})
  df.replace(to_replace={'gender': {0:'Male', 1:'Female'},
      'diabetes': {0:'Not Diabetes', 1:'Diabetes'}}, inplace=True)
  return df

# apply to datasets
categorization(df)

"""**Univariate Analysis**"""

# set canvas
plt.figure(figsize=(12,8))

# visualize pie plot
df['diabetes'].value_counts().plot.pie(explode=[0, 0.1], 
                                     autopct='%1.1f%%', 
                                     colors=['#7294f5','#fa2c50'], 
                                     startangle = 90, 
                                     shadow=False)
plt.title('Pie Chart')
plt.ylabel('')

plt.suptitle('distribution of people are affected by Diabetes')
# plt.subplots_adjust(hspace=0.5,wspace=0.5)
plt.show()
plt.savefig('foo.png')

"""Pada Pie Chart, dapat disimpulkan bahwa pengidap Diabetes lebih sedikit daripada orang yang tidak mengidap anemia yaitu sebesar 9.0%

**Coorelation *Body Mass Index* (BMI)**
"""

sns.set(rc = {'figure.figsize':(10,9)})
sns.boxplot(x='gender',y='bmi', hue='diabetes', palette={"Not Diabetes": "#7294f5", "Diabetes": "#fa2c50"}, data=df)

"""Pada visualisasi diatas, Orang yang terkena Diabetes, cenderung memiliki Body Mass Index yang lebih besar"""

sns.set(rc = {'figure.figsize':(6.4,4.8)})
sns.boxplot(y='age', x='diabetes', palette={"Not Diabetes": "#7294f5", "Diabetes": "#fa2c50"}, data=df)

sns.set(rc = {'figure.figsize':(6.4,4.8)})
sns.boxplot(y='HbA1c_level', x='diabetes', palette={"Not Diabetes": "#7294f5", "Diabetes": "#fa2c50"}, data=df)

sns.set(rc = {'figure.figsize':(6.4,4.8)})
sns.boxplot(y='blood_glucose_level', x='diabetes', palette={"Not Diabetes": "#7294f5", "Diabetes": "#fa2c50"}, data=df)

"""dari tiga visualiasi diatas, tidak ada perbedaan yang signifikan ditemukan."""

# pairplot
sns.pairplot(df, hue="diabetes")

# boxplot
sns.set_theme()
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(16, 4), constrained_layout=True)
plt.suptitle("Analysis Univariate Boxplot")
ax = ax.flatten()
colbox = df.iloc[:, 1:4]
for i, j in enumerate(colbox):
    sns.boxplot(x=df[j], ax=ax[i])

# histplot
fig, ax = plt.subplots(nrows=1,ncols=4, figsize=(16,4), constrained_layout=True)
plt.suptitle("Analisis Univariate Histogram")
ax=ax.flatten()
colhist = df.iloc[:, 1:5]
for i, j in enumerate(colhist):
    sns.histplot(df[j], ax=ax[i], kde=True, bins=50)

"""**Data Preparation**

satu langkah awal dalam Machine Learning untuk mempersiapkan data.
"""

# inverse to numerical
def inverse_categorization(data):
  df.replace(to_replace={'gender': {'Male':0, 'Female':1},
                         'diabetes': {'Not Diabetes':0, 'Diabetes':1}}, inplace=True)
  df.astype({'gender': 'int64'}, {'diabetes': 'int64'})
  return df

# apply to datasets
inverse_categorization(df)

df.info()

"""**Train-Test Split**

salah satu metode yang dapat digunakan untuk mengevaluasi performa model machine learning. Metode evaluasi model ini membagi dataset menjadi dua bagian yakni bagian yang digunakan untuk training data dan untuk testing data dengan proporsi tertentu. pada case ini, dataset akan dibagi dengan proporsi 20% yang akan digunakan sebagai data test. variabel X merupakan variabel untuk menampung attribut dan variabel y untuk menampung nilai class.
"""

# define x and y
X = df.drop('diabetes', axis=1).values
Y = df['diabetes'].values

"""Train data digunakan untuk fit model machine learning, sedangkan test data digunakan untuk mengevaluasi hasil fit model tersebut"""

# train-test split
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state=42)

print('X_train: {} records data'.format(len(X_train)))
print('y_train: {} records data'.format(len(y_train)))
print('X_test: {} records data'.format(len(X_test)))
print('y_test: {} records data'.format(len(y_test)))

"""Setelah melakukan splitting data, terdapat 75306 data yang akan digunakan sebagai data train (80%) dan 18827 data sebagai data testing (20%).

**Scaling Data**

bertujuan untuk menyeragamkan data agar sesuai dengan skala yang diinginkan. scaler yang digunakan adalah StandardScaler.
"""

# feature scaling
scaler = StandardScaler()
scaler.fit(X_train)

X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

# check scale data
X_train

X_test

"""**Imbalanced Classes**

Imbalance class merupakan kondisi dimana distribusi pada setiap label tidak seimbang. Hal ini, sangat umum ditemui dalam masalah pemodelan prediksi klasifikasi. perlu dilakukan penanganan terkait adanya kelas yang tidak seimbang. disini akan coba dilakukan handling menggunakan teknik oversampling meggunakan Synthetic Minority Oversampling Technique (SMOTE) adalah teknik statistik untuk meningkatkan data minoritas agar seimbang.
"""

# imbalanced class
df_y_train = pd.DataFrame(y_train)
df_y_train.value_counts().plot(kind='bar')
plt.xticks([0,1],['Not Diabetes','Diabetes'], rotation=0)
plt.xlabel('')
plt.title('Perbandingan Class (Before)')

# smote oversampling
smote = SMOTE(sampling_strategy = 1)
X_smote, y_smote = smote.fit_resample(X_train, y_train)

# check class
df_y_smote = pd.DataFrame(y_smote)
df_y_smote.value_counts().plot(kind='bar')
plt.xticks([0,1],['Not  Diabetes',' Diabetes'], rotation=0)
plt.xlabel('')
plt.title('Perbandingan Class (After)')

"""**Predictive Modelling**"""

# object model
modelKNN = KNeighborsClassifier(n_neighbors=8, metric='minkowski')
modelSVM = SVC(kernel='rbf')
modelRF = RandomForestClassifier(n_estimators=100)

# fitting
modelKNN.fit(X_smote, y_smote)
modelSVM.fit(X_smote, y_smote)
modelRF.fit(X_smote, y_smote)

# predict
y_predKNN = modelKNN.predict(X_test)
y_predSVM = modelSVM.predict(X_test)
y_predRF = modelRF.predict(X_test)

"""**Evaluation**"""

# conf-matrix
fig, ax = plt.subplots(nrows=1,ncols=3, figsize=(12,8))

conf_mat = confusion_matrix(y_test, y_predKNN)
sns.heatmap(conf_mat, ax=ax[0], square=True, annot=True, cmap='Blues', fmt='d', cbar=False)
ax[0].set_title('Confusion Matrix for KNN')

conf_mat = confusion_matrix(y_test, y_predSVM)
sns.heatmap(conf_mat, ax=ax[1], square=True, annot=True, cmap='Blues', fmt='d', cbar=False)
ax[1].set_title('Confusion Matrix for SVM')

conf_mat = confusion_matrix(y_test, y_predRF)
sns.heatmap(conf_mat, ax=ax[2], square=True, annot=True, cmap='Blues', fmt='d', cbar=False)
ax[2].set_title('Confusion Matrix for RF')

plt.subplots_adjust(wspace=0.5)
plt.show()

# acc_score
acc_score = pd.DataFrame(columns=['train', 'test'], index=['KNN','SVM','RF'])
model_dict = {'KNN': modelKNN, 'SVM': modelSVM, 'RF' : modelRF}
for name, model in model_dict.items():
    acc_score.loc[name, 'train'] = model.score(X_smote, y_smote)
    acc_score.loc[name, 'test'] = model.score(X_test, y_test)

acc_score

print(classification_report(y_test,y_predKNN))

# svm report
print(classification_report(y_test,y_predSVM))

# random-forest report
print(classification_report(y_test,y_predRF))

# report in dataframe
report_RF = classification_report(y_test,y_predRF, output_dict=True)
df_report = pd.DataFrame(report_RF).transpose()
df_report

"""Dari hasil diatas, model Random Forest merupakan model terbaik yang dikembangkan dengan nilai recall sebesar 96% yang bisa digunakan sebagai predictive modelling."""

